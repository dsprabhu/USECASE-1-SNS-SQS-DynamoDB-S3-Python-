# USECASE-1 ( SNS,SQS,DynamoDB,S3,Python)



# Architecture

![Watch the image](/Sree-usecase-1.png)

# Steps

- Step 1: Create SNS and SQS then Subscribe to Amazon SNS topic from SQS ( SNS --> SQS)
- Step 2: Create Lambda function , DynamoDB and integrated with SNS & SQS ( SNS --> SQS --> Lambda --> DynamoDB)
- Step 3: Trigger the Lambda function using of SQS 
- step 4: Create SQS, Lambda function and integrated to S3 ( SNS -->SQS --> Lambda --> S3)


#

# Step 1: Create SNS and SQS then Subscribe to Amazon SNS topic from SQS ( SNS --> SQS)

- Go to Amazon SNS --> Create topic --> Select standard --> Topic Name --> Create Topic
- Go to Amazon SQS --> Create queue --> Select Standard --> Queue Name --> Create Queue
- Open the Queue --> Go to SNS Subscriptions  --> Click Subscribe to Amazon SNS topic --> Select Amazon topic name --> Save
- Goto SNS --> Select Topic name --> Publish message --> Give subject and also Message like below
```
{
    "customer": 100,
    
    "items": [
        {
            "name": "produto 1", "amount": 10},
        {
            "name": "produto 2", "amount": 14.4}
    ]
}
```

-  Go to SQS --> Select queue name --> Click Send and Recive Message --> Poll for message --> click message --> select Body  --> OUTPUT

# Step 2: Create Lambda function , DynamoDB and integrated with SNS & SQS ( SNS --> SQS --> Lambda --> DynamoDB)


- Create Lambda --> Select Function name --> Runtime Python 3.6--> create function
- Click Run --> Give Event name & below code -- > Save then Run test it wil dispaly 200  output

```
{
  
  "Fooditem": "Product1"
  "Area": "Chennai"
}
```  
- Click DynamoDB --> create table --> Tablename "orders" --> Primary key "id"  --> create
- Goto Lambdo --> select the lambda function --> goto configuration --> permission --> clieck rolename --> Add polices --> AmazonDynamoDBFullAccess , AmazonSQS full access --> attached
- Goto Lambda code --> update like below --> Click deploy -->click Run 


```

import json
import uuid
import boto3
from decimal import Decimal


def lambda_handler(event, context):
    print(event)

    print("###############")

    dynamodb = boto3.resource("dynamodb")
    table = dynamodb.Table("orders")

    table.put_item(
        Item={
            "id": str(uuid.uuid4()),
            
             "content": {
                 "customer": 3,
                 "items": [
                     {"name": "teste 1", "amount": 10},
                     {"name": "teste 2", "amount": Decimal("13.4")},
                 ]
             }
        }
    )

    return {"statusCode": 200, "body": json.dumps("Hello from Lambda!")}
```

- You can able to see Output on  dynamodb Table 


# Step 3 : Trigger the Lambda function using of SQS

- Go to Lambda --> open the Function -->Add the trigger --> SQS --> provide sqs details --> click ADD
- Update Lambda function code like below  : --> Then Click Deploy

```
import json
import uuid
import boto3
from decimal import Decimal


def lambda_handler(event, context):
    print(event)

    body = json.loads(event["Records"][0]["body"])
    message = json.loads(body["Message"], parse_float=Decimal)
    print(body["Message"])
    print(message)
    print(type(message))

    dynamodb = boto3.resource("dynamodb")
    table = dynamodb.Table("orders")

    table.put_item(
        Item={
            "id": str(uuid.uuid4()),
            "content": message
            # "content": {
            #     "customer": 3,
            #     "items": [
            #         {"name": "teste 1", "amount": 10},
            #         {"name": "teste 2", "amount": Decimal("13.4")},
            #     ]
            # }
        }
    )

    return {"statusCode": 200, "body": json.dumps("Hello from Lambda!")}
```

- click on test tab --> test event action (create new event) , event name and update tempalte area as SQS then update below code --> save

```
{
    "Records": [
        {
            "messageId": "19dd0b57-b21e-4ac1-bd88-01bbb068cb78",
            "receiptHandle": "MessageReceiptHandle",
            "body": "{\"customer\": 2, \"age\": 27, \"phone\": 5516999999999, \"items\": [{\"name\": \"produto 1\", \"amount\": 10},{\"name\": \"produto 2\",\"amount\": 14.4}]}",
            "attributes": {
                "ApproximateReceiveCount": "1",
                "SentTimestamp": "1523232000000",
                "SenderId": "123456789012",
                "ApproximateFirstReceiveTimestamp": "1523232000001"
            },
            "messageAttributes": {},
            "md5OfBody": "{{{md5_of_body}}}",
            "eventSource": "aws:sqs",
            "eventSourceARN": "arn:aws:sqs:us-east-1:123456789012:MyQueue",
            "awsRegion": "us-east-1"
        }
    ]
}

```
- Now go to SNS and publish the msg it will automatcally save in dynamodb 

# Step 4: Create SQS, Lambda function and integrated to S3 ( SNS -->SQS --> Lambda --> s3)

- Create new lambda function --> Select  runtime python 3.6 --> Create  --> configuration --> permission --> add policy AmazonSQSFULLAccess , AmazonS3fullaccess --> save

- Update code like below code in Lambda --> deploy -->Test use default config  

```
import json
import boto3
from datetime import datetime


def lambda_handler(event, context):
    # TODO implement

    s3 = boto3.client("s3")

    body = json.loads(event["Records"][0]["body"])
    message = body["Message"]

    s3.put_object(
        Body=message,
        Bucket="test9999",
        Key=f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.txt",
    )

    return {"statusCode": 200, "body": json.dumps("Hello from Lambda!")}

```

- Create another SQS  same like above then  subscribe to existing SNS

- Create s3 bucket 
        bucket name --> test9999 remaing default config

- Go to Lambda2 --> add Trigger to SQS2 

- Now you can and publish the msg on sns it will publish both s3 and dynamo db

```
{
    "customer": 2,
    "age": 28,
    "phone": 5516999999999,
    "items": [
        {
            "name": "produto 1",
            "amount": 10
        },
        {
            "name": "produto 2",
            "amount": 14.4
        }
    ]
}

```


